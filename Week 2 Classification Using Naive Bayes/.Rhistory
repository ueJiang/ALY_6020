CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE,
dnn = c('predicted', 'actual'))
# Step 5 – improving model performance
sms_classifier2 <- naiveBayes(sms_train, sms_train_labels,
laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Step 2 – exploring and preparing the data
sms_raw <- read.csv("Roman Urdu DataSet", stringsAsFactors = FALSE)
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet", stringsAsFactors = FALSE)
getwd()
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet.csv", stringsAsFactors = FALSE)
str(ru_raw)
str(ru_raw)
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet.csv", stringsAsFactors = FALSE)
str(ru_raw)
ru_raw$Sentiment <- factor(ru_raw$Sentiment)
str(sms_raw$Sentiment)
str(ru_raw$Sentiment)
table(ru_raw$Sentiment)
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet.csv", stringsAsFactors = FALSE)
str(ru_raw)
ru_raw$Sentiment <- factor(ru_raw$Sentiment)
str(ru_raw$Sentiment)
table(ru_raw$Sentiment)
ru_raw$sentiment <- factor(ru_raw$sentiment)
str(ru_raw$Sentiment)
table(ru_raw$Sentiment)
str(ru_raw$sentiment)
table(ru_raw$sentiment)
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet.csv", stringsAsFactors = FALSE)
str(ru_raw)
ru_raw$sentiment <- factor(ru_raw$sentiment)
str(ru_raw$sentiment)
table(ru_raw$sentiment)
## Data preparation – cleaning and standardizing text data
library(tm)
ru_corpus <- VCorpus(VectorSource(ru_raw$comment))
print(ru_corpus)
inspect(ru_corpus[1:2])
as.character(ru_corpus[[1]])
lapply(ru_corpus[1:2], as.character)
print(ru_corpus)
ru_corpus_clean <- tm_map(ru_corpus,
content_transformer(tolower))
as.character(ru_corpus[[1]])
as.character(ru_corpus_clean[[1]])
ru_corpus_clean <- tm_map(ru_corpus_clean, removeNumbers)
ru_corpus_clean <- tm_map(ru_corpus_clean,
removeWords, stopwords())
ru_corpus_clean <- tm_map(ru_corpus_clean, removePunctuation)
library(SnowballC)
ru_corpus_clean <- tm_map(ru_corpus_clean, stemDocument)
ru_corpus_clean <- tm_map(ru_corpus_clean, stripWhitespace)
## Data preparation – splitting text documents into words
ru_dtm <- DocumentTermMatrix(ru_corpus_clean)
ru_dtm2 <- DocumentTermMatrix(ru_corpus, control = list(
tolower = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE
))
## Data preparation – creating training and test datasets
ru_dtm_train <- ru_dtm[1:8475, ]
ru_dtm_test <- ru_dtm[8476:11300, ]
ru_train_labels <- ru_raw[1:8475, ]$sentiment
ru_test_labels <- ru_raw[8476:11300, ]$sentiment
prop.table(table(ru_train_labels))
prop.table(table(ru_test_labels))
## Visualizing text data – word clouds
library(wordcloud)
wordcloud(ru_corpus_clean, min.freq = 50, random.order = FALSE)
neg <- subset(ru_raw, sentiment == "Negative")
pos <- subset(ru_raw, sentiment == "Positive")
wordcloud(neg$comment, max.words = 40, scale = c(3, 0.5))
wordcloud(pos$comment, max.words = 40, scale = c(3, 0.5))
## Data preparation – creating indicator features for frequent words
findFreqTerms(ru_dtm_train, 5)
ru_freq_words <- findFreqTerms(ru_dtm_train, 5)
str(ru_freq_words)
ru_dtm_freq_train<- ru_dtm_train[ , ru_freq_words]
ru_dtm_freq_test <- ru_dtm_test[ , ru_freq_words]
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
ru_train <- apply(ru_dtm_freq_train, MARGIN = 2,
convert_counts)
ru_test <- apply(ru_dtm_freq_test, MARGIN = 2,
convert_counts)
# Step 3 – training a model on the data
library(e1071)
ru_classifier <- naiveBayes(ru_train, ru_train_labels)
# Step 4 – evaluating model performance
ru_test_pred <- predict(ru_classifier, ru_test)
library(gmodels)
CrossTable(ru_test_pred, ru_test_labels,
prop.chisq = FALSE, prop.t = FALSE,
dnn = c('predicted', 'actual'))
# Step 4 – evaluating model performance
ru_test_pred <- predict(ru_classifier, ru_test)
library(gmodels)
CrossTable(ru_test_pred, ru_test_labels,
prop.chisq = FALSE, prop.t = FALSE,
dnn = c('predicted', 'actual'))
# Step 5 – improving model performance
ru_classifier2 <- naiveBayes(ru_train, ru_train_labels,
laplace = 1)
ru_test_pred2 <- predict(ru_classifier2, ru_test)
CrossTable(ru_test_pred2, ru_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet3.csv", stringsAsFactors = FALSE)
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman Urdu DataSet3.csv", stringsAsFactors = FALSE)
str(ru_raw)
ru_raw$sentiment <- factor(ru_raw$sentiment)
str(ru_raw$sentiment)
table(ru_raw$sentiment)
## Data preparation – cleaning and standardizing text data
library(tm)
ru_corpus <- VCorpus(VectorSource(ru_raw$comment))
print(ru_corpus)
ru_corpus_clean <- tm_map(ru_corpus,
content_transformer(tolower))
as.character(ru_corpus[[1]])
as.character(ru_corpus_clean[[1]])
ru_corpus_clean <- tm_map(ru_corpus_clean, removeNumbers)
ru_corpus_clean <- tm_map(ru_corpus_clean,
removeWords, stopwords())
ru_corpus_clean <- tm_map(ru_corpus_clean, removePunctuation)
library(SnowballC)
ru_corpus_clean <- tm_map(ru_corpus_clean, stemDocument)
ru_corpus_clean <- tm_map(ru_corpus_clean, stripWhitespace)
## Data preparation – splitting text documents into words
ru_dtm <- DocumentTermMatrix(ru_corpus_clean)
## Data preparation – creating training and test datasets
ru_dtm_train <- ru_dtm[1:8475, ]
ru_dtm_test <- ru_dtm[8476:11300, ]
ru_train_labels <- ru_raw[1:8475, ]$sentiment
ru_test_labels <- ru_raw[8476:11300, ]$sentiment
prop.table(table(ru_train_labels))
prop.table(table(ru_test_labels))
## Visualizing text data – word clouds
library(wordcloud)
set.seed(9850)
gp <- runif(nrow(ru_raw))
gp
ru_raw <- ru_raw[order(gp)]
ru_raw <- ru_raw[order(gp), ]
str(ru_raw)
head(ru_raw)
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet.csv", stringsAsFactors = FALSE)
str(ru_raw)
set.seed(9850)
gp <- runif(nrow(ru_raw))
ru_raw <- ru_raw[order(gp), ]
head(ru_raw)
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet.csv", stringsAsFactors = FALSE)
str(ru_raw)
set.seed(9850)
gp <- runif(nrow(ru_raw))
ru_raw <- ru_raw[order(gp), ]
head(ru_raw)
ru_raw$sentiment <- factor(ru_raw$sentiment)
str(ru_raw$sentiment)
table(ru_raw$sentiment)
## Data preparation – cleaning and standardizing text data
library(tm)
ru_corpus <- VCorpus(VectorSource(ru_raw$comment))
print(ru_corpus)
ru_corpus_clean <- tm_map(ru_corpus,
content_transformer(tolower))
as.character(ru_corpus[[1]])
as.character(ru_corpus_clean[[1]])
ru_corpus_clean <- tm_map(ru_corpus_clean, removeNumbers)
ru_corpus_clean <- tm_map(ru_corpus_clean,
removeWords, stopwords())
ru_corpus_clean <- tm_map(ru_corpus_clean, removePunctuation)
library(SnowballC)
ru_corpus_clean <- tm_map(ru_corpus_clean, stemDocument)
ru_corpus_clean <- tm_map(ru_corpus_clean, stripWhitespace)
## Data preparation – splitting text documents into words
ru_dtm <- DocumentTermMatrix(ru_corpus_clean)
## Data preparation – creating training and test datasets
ru_dtm_train <- ru_dtm[1:8475, ]
ru_dtm_test <- ru_dtm[8476:11300, ]
ru_train_labels <- ru_raw[1:8475, ]$sentiment
ru_test_labels <- ru_raw[8476:11300, ]$sentiment
prop.table(table(ru_train_labels))
prop.table(table(ru_test_labels))
## Visualizing text data – word clouds
library(wordcloud)
wordcloud(ru_corpus_clean, min.freq = 50, random.order = FALSE)
neg <- subset(ru_raw, sentiment == "Negative")
pos <- subset(ru_raw, sentiment == "Positive")
wordcloud(neg$comment, max.words = 40, scale = c(3, 0.5))
wordcloud(pos$comment, max.words = 40, scale = c(3, 0.5))
## Data preparation – creating indicator features for frequent words
findFreqTerms(ru_dtm_train, 5)
ru_freq_words <- findFreqTerms(ru_dtm_train, 5)
str(ru_freq_words)
ru_dtm_freq_train<- ru_dtm_train[ , ru_freq_words]
ru_dtm_freq_test <- ru_dtm_test[ , ru_freq_words]
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
ru_train <- apply(ru_dtm_freq_train, MARGIN = 2,
convert_counts)
ru_test <- apply(ru_dtm_freq_test, MARGIN = 2,
convert_counts)
# Step 3 – training a model on the data
library(e1071)
ru_classifier <- naiveBayes(ru_train, ru_train_labels)
# Step 4 – evaluating model performance
ru_test_pred <- predict(ru_classifier, ru_test)
library(gmodels)
CrossTable(ru_test_pred, ru_test_labels,
prop.chisq = FALSE, prop.t = FALSE,
dnn = c('predicted', 'actual'))
# Step 5 – improving model performance
ru_classifier2 <- naiveBayes(ru_train, ru_train_labels,
laplace = 1)
ru_test_pred2 <- predict(ru_classifier2, ru_test)
CrossTable(ru_test_pred2, ru_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet.csv", stringsAsFactors = FALSE)
str(ru_raw)
set.seed(9850)
gp <- runif(nrow(ru_raw))
ru_raw <- ru_raw[order(gp), ]
ru_raw$sentiment <- factor(ru_raw$sentiment)
str(ru_raw$sentiment)
table(ru_raw$sentiment)
## Data preparation – cleaning and standardizing text data
library(tm)
ru_corpus <- VCorpus(VectorSource(ru_raw$comment))
print(ru_corpus)
ru_corpus_clean <- tm_map(ru_corpus,
content_transformer(tolower))
as.character(ru_corpus[[1]])
as.character(ru_corpus_clean[[1]])
ru_corpus_clean <- tm_map(ru_corpus_clean, removeNumbers)
#ru_corpus_clean <- tm_map(ru_corpus_clean,
#                           removeWords, stopwords())
ru_corpus_clean <- tm_map(ru_corpus_clean, removePunctuation)
library(SnowballC)
#ru_corpus_clean <- tm_map(ru_corpus_clean, stemDocument)
ru_corpus_clean <- tm_map(ru_corpus_clean, stripWhitespace)
## Data preparation – splitting text documents into words
ru_dtm <- DocumentTermMatrix(ru_corpus_clean)
## Data preparation – creating training and test datasets
ru_dtm_train <- ru_dtm[1:8475, ]
ru_dtm_test <- ru_dtm[8476:11300, ]
ru_train_labels <- ru_raw[1:8475, ]$sentiment
ru_test_labels <- ru_raw[8476:11300, ]$sentiment
prop.table(table(ru_train_labels))
prop.table(table(ru_test_labels))
## Visualizing text data – word clouds
library(wordcloud)
wordcloud(ru_corpus_clean, min.freq = 50, random.order = FALSE)
neg <- subset(ru_raw, sentiment == "Negative")
pos <- subset(ru_raw, sentiment == "Positive")
wordcloud(neg$comment, max.words = 40, scale = c(3, 0.5))
wordcloud(pos$comment, max.words = 40, scale = c(3, 0.5))
## Data preparation – creating indicator features for frequent words
findFreqTerms(ru_dtm_train, 5)
ru_freq_words <- findFreqTerms(ru_dtm_train, 5)
str(ru_freq_words)
ru_dtm_freq_train<- ru_dtm_train[ , ru_freq_words]
ru_dtm_freq_test <- ru_dtm_test[ , ru_freq_words]
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
ru_train <- apply(ru_dtm_freq_train, MARGIN = 2,
convert_counts)
ru_test <- apply(ru_dtm_freq_test, MARGIN = 2,
convert_counts)
# Step 3 – training a model on the data
library(e1071)
ru_classifier <- naiveBayes(ru_train, ru_train_labels)
# Step 4 – evaluating model performance
ru_test_pred <- predict(ru_classifier, ru_test)
library(gmodels)
CrossTable(ru_test_pred, ru_test_labels,
prop.chisq = FALSE, prop.t = FALSE,
dnn = c('predicted', 'actual'))
# Step 5 – improving model performance
ru_classifier2 <- naiveBayes(ru_train, ru_train_labels,
laplace = 1)
ru_test_pred2 <- predict(ru_classifier2, ru_test)
CrossTable(ru_test_pred2, ru_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Step 2 – exploring and preparing the data
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
str(sms_raw)
sms_raw$type <- factor(sms_raw$type)
str(sms_raw$type)
table(sms_raw$type)
## Data preparation – cleaning and standardizing text data
library(tm)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2], as.character)
sms_corpus_clean <- tm_map(sms_corpus,
content_transformer(tolower))
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)
sms_corpus_clean <- tm_map(sms_corpus_clean,
removeWords, stopwords())
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)
library(SnowballC)
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace)
## Data preparation – splitting text documents into words
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm
## Data preparation – splitting text documents into words
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm2 <- DocumentTermMatrix(sms_corpus, control = list(
tolower = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE
))
sms_dtm
sms_dtm2
## Data preparation – creating training and test datasets
sms_dtm_train <- sms_dtm[1:4180, ]
sms_dtm_test <- sms_dtm[4181:5574, ]
sms_train_labels <- sms_raw[1:4180, ]$type
sms_test_labels <- sms_raw[4181:5574, ]$type
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
## Visualizing text data – word clouds
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
spam <- subset(sms_raw, type == "spam")
ham <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
## Data preparation – creating indicator features for frequent words
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)
sms_dtm_freq_train<- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2,
convert_counts)
sms_test <- apply(sms_dtm_freq_test, MARGIN = 2,
convert_counts)
sms_train
str(sms_train)
View(sms_test)
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2,
convert_counts)
sms_test <- apply(sms_dtm_freq_test, MARGIN = 2,
convert_counts)
View(sms_test)
View(sms_train)
# Step 3 – training a model on the data
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
sms_classifier
# Step 3 – training a model on the data
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
# Step 4 – evaluating model performance
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE,
dnn = c('predicted', 'actual'))
# Step 5 – improving model performance
sms_classifier2 <- naiveBayes(sms_train, sms_train_labels,
laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet.csv", stringsAsFactors = FALSE)
str(ru_raw)
set.seed(9850)
gp <- runif(nrow(ru_raw))
ru_raw <- ru_raw[order(gp), ]
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet.csv", stringsAsFactors = FALSE)
str(ru_raw)
head(ru_raw)
View(ru_raw)
# Step 2 – exploring and preparing the data
ru_raw <- read.csv("Roman_Urdu_DataSet.csv", stringsAsFactors = FALSE)
str(ru_raw)
set.seed(9850)
gp <- runif(nrow(ru_raw))
ru_raw <- ru_raw[order(gp), ]
ru_raw$sentiment <- factor(ru_raw$sentiment)
str(ru_raw$sentiment)
table(ru_raw$sentiment)
## Data preparation – cleaning and standardizing text data
library(tm)
ru_corpus <- VCorpus(VectorSource(ru_raw$comment))
print(ru_corpus)
ru_corpus_clean <- tm_map(ru_corpus,
content_transformer(tolower))
as.character(ru_corpus[[1]])
as.character(ru_corpus_clean[[1]])
ru_corpus_clean <- tm_map(ru_corpus_clean, removeNumbers)
ru_corpus_clean <- tm_map(ru_corpus_clean,
removeWords, stopwords())
ru_corpus_clean <- tm_map(ru_corpus_clean, removePunctuation)
library(SnowballC)
ru_corpus_clean <- tm_map(ru_corpus_clean, stemDocument)
ru_corpus_clean <- tm_map(ru_corpus_clean, stripWhitespace)
ru_corpus_clean <- tm_map(ru_corpus,
content_transformer(tolower))
ru_corpus_clean <- tm_map(ru_corpus_clean, removeNumbers)
ru_corpus_clean <- tm_map(ru_corpus_clean,
removeWords, stopwords())
ru_corpus_clean <- tm_map(ru_corpus_clean, removePunctuation)
library(SnowballC)
ru_corpus_clean <- tm_map(ru_corpus_clean, stemDocument)
ru_corpus_clean <- tm_map(ru_corpus_clean, stripWhitespace)
ru_corpus_clean <- tm_map(ru_corpus,
content_transformer(tolower))
ru_corpus_clean <- tm_map(ru_corpus_clean, removeNumbers)
ru_corpus_clean <- tm_map(ru_corpus_clean,
removeWords, stopwords())
ru_corpus_clean <- tm_map(ru_corpus_clean, removePunctuation)
ru_corpus_clean <- tm_map(ru_corpus_clean, stemDocument)
ru_corpus_clean <- tm_map(ru_corpus_clean, stripWhitespace)
## Data preparation – splitting text documents into words
ru_dtm <- DocumentTermMatrix(ru_corpus_clean)
## Data preparation – creating training and test datasets
ru_dtm_train <- ru_dtm[1:8475, ]
ru_dtm_test <- ru_dtm[8476:11300, ]
ru_train_labels <- ru_raw[1:8475, ]$sentiment
ru_test_labels <- ru_raw[8476:11300, ]$sentiment
prop.table(table(ru_train_labels))
prop.table(table(ru_test_labels))
wordcloud(ru_corpus_clean, min.freq = 50, random.order = FALSE)
neg <- subset(ru_raw, sentiment == "Negative")
pos <- subset(ru_raw, sentiment == "Positive")
wordcloud(neg$comment, max.words = 40, scale = c(3, 0.5))
wordcloud(pos$comment, max.words = 40, scale = c(3, 0.5))
## Data preparation – creating indicator features for frequent words
findFreqTerms(ru_dtm_train, 5)
ru_freq_words <- findFreqTerms(ru_dtm_train, 5)
str(ru_freq_words)
ru_dtm_freq_train<- ru_dtm_train[ , ru_freq_words]
ru_dtm_freq_test <- ru_dtm_test[ , ru_freq_words]
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
ru_train <- apply(ru_dtm_freq_train, MARGIN = 2,
convert_counts)
ru_test <- apply(ru_dtm_freq_test, MARGIN = 2,
convert_counts)
## Data preparation – creating indicator features for frequent words
ru_freq_words <- findFreqTerms(ru_dtm_train, 5)
str(ru_freq_words)
ru_dtm_freq_train <- ru_dtm_train[ , ru_freq_words]
ru_dtm_freq_test <- ru_dtm_test[ , ru_freq_words]
ru_train <- apply(ru_dtm_freq_train, MARGIN = 2,
convert_counts)
ru_test <- apply(ru_dtm_freq_test, MARGIN = 2,
convert_counts)
View(ru_train)
ru_classifier <- naiveBayes(ru_train, ru_train_labels)
# Step 3 – training a model on the data
library(e1071)
ru_classifier <- naiveBayes(ru_train, ru_train_labels)
# Step 4 – evaluating model performance
ru_test_pred <- predict(ru_classifier, ru_test)
CrossTable(ru_test_pred, ru_test_labels,
prop.chisq = FALSE, prop.t = FALSE,
dnn = c('predicted', 'actual'))
# Step 5 – improving model performance
ru_classifier2 <- naiveBayes(ru_train, ru_train_labels,
laplace = 1)
ru_test_pred2 <- predict(ru_classifier2, ru_test)
CrossTable(ru_test_pred2, ru_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
View(ru_raw)
View(ru_dtm)
View(ru_test)
View(neg)
